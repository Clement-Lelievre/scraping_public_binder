{
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Démo - scraping"
      ],
      "metadata": {
        "id": "24b6cd55-9ca2-4e5d-880e-db917fbd1038"
      },
      "id": "24b6cd55-9ca2-4e5d-880e-db917fbd1038"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "59344071-0002-4d60-b3bf-664f6d9cb0f9"
      },
      "id": "59344071-0002-4d60-b3bf-664f6d9cb0f9"
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup  # parser de HTML/XML\n",
        "import requests  # pour la query HTTP\n",
        "import pandas as pd # analyse de données, sauvegarde au format excel/CSV/JSON/Parquet etc. (on pourrait n'utiliser que la lib csv)"
      ],
      "metadata": {
        "trusted": true,
        "tags": [],
        "id": "7662d776-72b5-44d7-8224-3a8cb9cb3286"
      },
      "execution_count": 1,
      "outputs": [],
      "id": "7662d776-72b5-44d7-8224-3a8cb9cb3286"
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://books.toscrape.com/\"  # stockée dans une constante\n",
        "\n",
        "# TO DO: visiter le site ci-dessus, regarder son code"
      ],
      "metadata": {
        "trusted": true,
        "tags": [],
        "id": "21cc998a-79f3-4ff2-b139-95d4609fc376"
      },
      "execution_count": 2,
      "outputs": [],
      "id": "21cc998a-79f3-4ff2-b139-95d4609fc376"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Récupérer les noms des catégories (colonne de gauche)"
      ],
      "metadata": {
        "id": "d89e2f63-47cd-47df-9a35-b48c7562275a"
      },
      "id": "d89e2f63-47cd-47df-9a35-b48c7562275a"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_categories() -> None:  # type hint\n",
        "    \"\"\"Capture les noms de catégories de la colonne de gauche\"\"\"\n",
        "    r = requests.get(URL)\n",
        "    if (rsc := r.status_code) != 200:\n",
        "        print(f\"Erreur, code {rsc}\")\n",
        "    else:\n",
        "        html = r.content\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "        categories = []\n",
        "        for elem in soup.find_all('a'):\n",
        "            if elem.get('href', '').startswith('catalogue/category/books/'):\n",
        "                category = elem.text.strip()\n",
        "                categories.append(category)\n",
        "        print(f\"{len(categories)} categories found:\\n {categories}\")"
      ],
      "metadata": {
        "trusted": true,
        "tags": [],
        "id": "1122846b-f4d9-4994-a344-3d3ef439139d"
      },
      "execution_count": 3,
      "outputs": [],
      "id": "1122846b-f4d9-4994-a344-3d3ef439139d"
    },
    {
      "cell_type": "code",
      "source": [
        "get_categories.__doc__"
      ],
      "metadata": {
        "trusted": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "af121e93-ab15-4b1d-b6de-1f8771c15505",
        "outputId": "1e49b00a-7d97-4bdf-8443-e7f0c6b0f499"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Capture les noms de catégories de la colonne de gauche'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "id": "af121e93-ab15-4b1d-b6de-1f8771c15505"
    },
    {
      "cell_type": "code",
      "source": [
        "get_categories()"
      ],
      "metadata": {
        "trusted": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f63133ef-18ed-4f0b-9c1c-64c0588b0544",
        "outputId": "fc310cd8-06e1-4a73-98b6-383a16024615"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 categories found:\n",
            " ['Travel', 'Mystery', 'Historical Fiction', 'Sequential Art', 'Classics', 'Philosophy', 'Romance', 'Womens Fiction', 'Fiction', 'Childrens', 'Religion', 'Nonfiction', 'Music', 'Default', 'Science Fiction', 'Sports and Games', 'Add a comment', 'Fantasy', 'New Adult', 'Young Adult', 'Science', 'Poetry', 'Paranormal', 'Art', 'Psychology', 'Autobiography', 'Parenting', 'Adult Fiction', 'Humor', 'Horror', 'History', 'Food and Drink', 'Christian Fiction', 'Business', 'Biography', 'Thriller', 'Contemporary', 'Spirituality', 'Academic', 'Self Help', 'Historical', 'Christian', 'Suspense', 'Short Stories', 'Novels', 'Health', 'Politics', 'Cultural', 'Erotica', 'Crime']\n"
          ]
        }
      ],
      "id": "f63133ef-18ed-4f0b-9c1c-64c0588b0544"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Récupérer les titres des livres"
      ],
      "metadata": {
        "id": "275a0f04-7707-4f11-98f4-302c64878af9"
      },
      "id": "275a0f04-7707-4f11-98f4-302c64878af9"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_titles() -> None:\n",
        "    \"\"\"Capture les titres de livres\"\"\"\n",
        "    r = requests.get(URL)\n",
        "    if (rsc := r.status_code) != 200:\n",
        "        print(f\"Erreur, code {rsc}\")\n",
        "    else:\n",
        "        html = r.content\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "        titles = []\n",
        "        for elem in soup.find_all('h3'):\n",
        "            try:\n",
        "                if elem.a.get('href', '').startswith('catalogue/'):\n",
        "                    titles.append(elem.a.get('title','').strip())\n",
        "            except AttributeError:\n",
        "                continue\n",
        "        print(f\"{len(titles)} titles found:\\n {titles}\")"
      ],
      "metadata": {
        "trusted": true,
        "tags": [],
        "id": "d65bbff3-2e3e-4b86-9ef1-dc1101992d68"
      },
      "execution_count": 20,
      "outputs": [],
      "id": "d65bbff3-2e3e-4b86-9ef1-dc1101992d68"
    },
    {
      "cell_type": "code",
      "source": [
        "get_titles()"
      ],
      "metadata": {
        "trusted": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8ad5048-ee53-47fa-956b-9b39a294cac4",
        "outputId": "7b18e9e8-5b62-4b61-a2ed-68dcd6fac5cf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 titles found:\n",
            " ['A Light in the Attic', 'Tipping the Velvet', 'Soumission', 'Sharp Objects', 'Sapiens: A Brief History of Humankind', 'The Requiem Red', 'The Dirty Little Secrets of Getting Your Dream Job', 'The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull', 'The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics', 'The Black Maria', 'Starving Hearts (Triangular Trade Trilogy, #1)', \"Shakespeare's Sonnets\", 'Set Me Free', \"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\", 'Rip it Up and Start Again', 'Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991', 'Olio', 'Mesaerion: The Best Science Fiction Stories 1800-1849', 'Libertarianism for Beginners', \"It's Only the Himalayas\"]\n"
          ]
        }
      ],
      "id": "e8ad5048-ee53-47fa-956b-9b39a294cac4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Récupérer les titres des livres **des 3 premières pages**"
      ],
      "metadata": {
        "id": "3eblSW32HDWN"
      },
      "id": "3eblSW32HDWN"
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "def get_titles_multipage(page_start: int, page_end: int) -> None:\n",
        "    \"\"\"Capture les titres de livres de la page `page_start` à la page `page_end`\"\"\"\n",
        "\n",
        "    # on remarque un pattern d'URL: https://books.toscrape.com/catalogue/page-2.html\n",
        "    URL = 'https://books.toscrape.com/catalogue/page-{}.html'\n",
        "    titles = {nb: [] for nb in range(page_start, page_end + 1)}  # or use a defaultdict(list)\n",
        "\n",
        "    for page_nb in range(page_start, page_end + 1):\n",
        "      url = URL.format(page_nb)\n",
        "      print(f\"Scraping {url}...\")\n",
        "      r = requests.get(url)\n",
        "      if (rsc := r.status_code) != 200:\n",
        "          print(f\"Erreur, code {rsc}\")\n",
        "      else:\n",
        "          html = r.content\n",
        "          soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "          for elem in soup.find_all('h3'):\n",
        "              try:\n",
        "                  if elem.a.get('href'):  # this time there is no \"/catalogue\"\n",
        "                      titles[page_nb].append(elem.a.get('title','').strip())\n",
        "              except AttributeError:\n",
        "                  continue\n",
        "    pprint(titles)"
      ],
      "metadata": {
        "id": "f3b92f33-f9be-4f28-b426-9b4df7628620"
      },
      "execution_count": 25,
      "outputs": [],
      "id": "f3b92f33-f9be-4f28-b426-9b4df7628620"
    },
    {
      "cell_type": "code",
      "source": [
        "get_titles_multipage(1, 3)"
      ],
      "metadata": {
        "id": "Kp2KawQVIDqJ"
      },
      "id": "Kp2KawQVIDqJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quel est le coût total des 4 premiers livres?"
      ],
      "metadata": {
        "id": "P_Ifsn0mJnE3"
      },
      "id": "P_Ifsn0mJnE3"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_total_price(n_books : int = 4) -> None:\n",
        "    \"\"\"Calcule la somme des prix des `n_books` premiers livres\"\"\"\n",
        "    r = requests.get(URL)\n",
        "    if (rsc := r.status_code) != 200:\n",
        "        print(f\"Erreur, code {rsc}\")\n",
        "    else:\n",
        "        html = r.content\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "        prices = []\n",
        "        for elem in soup.find_all('div', class_='product_price')[:n_books]:\n",
        "            try:\n",
        "                prices.append(elem.p.text.strip()[1:])  # drop £ sign\n",
        "            except AttributeError:\n",
        "                continue\n",
        "        prices = [float(val) for val in prices]  # or list(map(float, prices))\n",
        "        print(f\"{prices=}, sum : {sum(prices)}\")"
      ],
      "metadata": {
        "id": "2YFieesxJq0L"
      },
      "id": "2YFieesxJq0L",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_total_price()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO_66VrlLCX4",
        "outputId": "99326ca3-e810-4999-f3d3-020e00910809"
      },
      "id": "tO_66VrlLCX4",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prices=[51.77, 53.74, 50.1, 47.82], sum : 203.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stocker en local l'image de couverture de \"Sapiens\""
      ],
      "metadata": {
        "id": "rmhD34xHLWXf"
      },
      "id": "rmhD34xHLWXf"
    },
    {
      "cell_type": "code",
      "source": [
        "def store_bookcover() -> None:\n",
        "    r = requests.get(URL)\n",
        "    if (rsc := r.status_code) != 200:\n",
        "        print(f\"Erreur, code {rsc}\")\n",
        "    else:\n",
        "        html = r.content\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "        for elem in soup.find_all('div', class_=\"image_container\"):\n",
        "          if \"sapiens\" in elem.a.get('href', '').lower():\n",
        "              img_url = \"\".join(['https://books.toscrape.com/', elem.a.img.get('src', '')])\n",
        "              print(f\"{img_url=}\")\n",
        "              img_req = requests.get(img_url)\n",
        "              with open('sapiens.jpg', 'wb') as f:\n",
        "                  f.write(img_req.content)\n",
        "              break\n",
        "        else:\n",
        "          print('No bookcover from Sapiens found')"
      ],
      "metadata": {
        "id": "IeaQiF93LcsI"
      },
      "id": "IeaQiF93LcsI",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_bookcover()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZMVXSWlNQ1s",
        "outputId": "a0733b3d-2e0a-43d6-a3d3-1d8985ebcd76"
      },
      "id": "UZMVXSWlNQ1s",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img_url='https://books.toscrape.com/media/cache/be/a5/bea5697f2534a2f86a3ef27b5a8c12a6.jpg'\n"
          ]
        }
      ]
    }
  ]
}